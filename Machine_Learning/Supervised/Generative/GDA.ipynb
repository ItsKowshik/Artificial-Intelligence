{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Discriminant Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from scipy.stats import multivariate_normal\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86f505df95145da8adb42a070beb297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='mu1', max=3.0, min=-3.0), FloatSlider(value=0.0, desâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This is to interact and change the value of the parameters\n",
    "@interact(mu1=(-3,3,0.1),  mu2=(-3,3.0,0.1), diagonal_1=(0,3.0,0.1), diagonal_2=(0,3.0,0.1), non_diagonal=(-3,3.0,0.1))\n",
    "def visualize_multivariate_gaussian(mu1=0.0, mu2=0.0, diagonal_1=1, diagonal_2=1, non_diagonal=0):\n",
    "    # This code snippet is taken from here [https://scipython.com/blog/visualizing-the-bivariate-gaussian-distribution/]\n",
    "    N = 300                         # number of observations\n",
    "    X = np.linspace(-3, 3, N)   # initial   values  for the input\n",
    "    Y = np.linspace(-3, 4, N)   # initial values for the Gaussian distribution\n",
    "    X, Y = np.meshgrid(X, Y)     # Make a grid of coordinates\n",
    "\n",
    "    # Mean vector and covariance matrix\n",
    "    mu = np.array([mu1, mu2])\n",
    "    Sigma = np.array([[ diagonal_1 , non_diagonal], [non_diagonal,  diagonal_2]])\n",
    "    print(\"ðœ‡ = \", mu)\n",
    "    print(\"Î£ = \", Sigma)\n",
    "    # Pack X and Y into a single 3-dimensional array\n",
    "    pos = np.empty(X.shape + (2,))\n",
    "    pos[:, :, 0] = X\n",
    "    pos[:, :, 1] = Y\n",
    "\n",
    "    def multivariate_gaussian(pos, mu, Sigma):\n",
    "        \"\"\"Return the multivariate Gaussian distribution on array pos.\n",
    "\n",
    "        pos is an array constructed by packing the meshed arrays of variables\n",
    "        x_1, x_2, x_3, ..., x_k into its _last_ dimension.\n",
    "\n",
    "        \"\"\"\n",
    "        # Calculate the multivariate Gaussian distribution\n",
    "        n = mu.shape[0]\n",
    "        Sigma_det = np.linalg.det(Sigma)\n",
    "        Sigma_inv = np.linalg.inv(Sigma)\n",
    "        N = np.sqrt((2*np.pi)**n * Sigma_det)\n",
    "        # This einsum call calculates (x-mu)T.Sigma-1.(x-mu) in a vectorized\n",
    "        # way across all the input variables.\n",
    "        fac = np.einsum('...k,kl,...l->...', pos-mu, Sigma_inv, pos-mu)\n",
    "\n",
    "        return np.exp(-fac / 2) / N\n",
    "\n",
    "    # The distribution on the variables X, Y packed into pos.\n",
    "    Z = multivariate_gaussian(pos, mu, Sigma)\n",
    "\n",
    "    # Create a surface plot and projected filled contour plot under it.\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.plot_surface(X, Y, Z, rstride=3, cstride=3, linewidth=1, antialiased=True,\n",
    "                    cmap=cm.viridis)\n",
    "    cset = ax.contourf(X, Y, Z, zdir='z', offset=-0.15, cmap=cm.viridis)\n",
    "\n",
    "    # Adjust the limits, ticks and view angle\n",
    "    ax.set_zlim(-0.15,0.2)\n",
    "    ax.set_zticks(np.linspace(0,0.2,5))\n",
    "    ax.view_init(27, -21)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x_train, y_train):\n",
    "    m = y_train.shape[0] # Number of training example\n",
    "    #Reshapeing the training set\n",
    "    x_train = x_train.reshape(m, -1)\n",
    "    input_feature = x_train.shape[1] # Number of input feature. In our case it's 4\n",
    "    class_label = len(np.unique(y_train.reshape(-1))) # Number of class. In our case its 3.\n",
    "    \n",
    "    # Start everything with zero first.\n",
    "    # Mean for each class. Each row contains an individual class. And each of the class input is 4 dimenstional\n",
    "    mu = np.zeros((class_label, input_feature))\n",
    "    # Each row will conatain the covariance matrix of each class.\n",
    "    # The covariance matrix is a square symettric matrix.\n",
    "    # It indicates how each of the input feature varies with each other.\n",
    "    sigma = np.zeros((class_label, input_feature, input_feature))\n",
    "    # Prior probability of each class.\n",
    "    # Its the measure of knowing the likelihood of any class before seeing the input data.\n",
    "    phi = np.zeros(class_label)\n",
    "\n",
    "    for label in range(class_label):\n",
    "        # Seperate all the training data for a single class\n",
    "        indices = (y_train == label)\n",
    "        # The optimized parameter equationn\n",
    "        phi[label] = float(np.sum(indices)) / m\n",
    "        mu[label] = np.mean(x_train[indices, :], axis=0)\n",
    "        # Instead of writting the equation we used numpy covariance function. \n",
    "        sigma[label] = np.cov(x_train[indices, :], rowvar=0)\n",
    "    \n",
    "    return phi, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_tests, phi, mu, sigma):\n",
    "    # flatten the training data\n",
    "    x_tests = x_tests.reshape(x_tests.shape[0], -1)\n",
    "    class_label = mu.shape[0] # Number of label we have in our case it's k = 3\n",
    "    scores = np.zeros((x_tests.shape[0], class_label))  # Initially we set the each class probability to zero.\n",
    "    for label in range(class_label): # We will calculate the probability for each of the class.\n",
    "        # normal_distribution_prob.logpdf Will give us the log value of the PDF that we just mentioned above.\n",
    "        normal_distribution_prob = multivariate_normal(mean=mu[label], cov=sigma[label])\n",
    "        # x_test can have multiple test data we will calculate the probability of each of the test data\n",
    "        for i, x_test in enumerate(x_tests):\n",
    "            scores[i, label] = np.log(phi[label]) + normal_distribution_prob.logpdf(x_test)\n",
    "    predictions = np.argmax(scores, axis=1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score of our model:  0.9473684210526315\n",
      "f1 score of scikit-learn model is:  0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "data = load_iris()\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.data, data.target)\n",
    "phi, mu, sigma = fit(x_train, y_train)\n",
    "y_predict = predict(x_test, phi, mu, sigma)\n",
    "score = f1_score(y_test, y_predict, average=\"weighted\")\n",
    "print(\"f1 score of our model: \", score)\n",
    "\n",
    "# Compare this model with scikitlearn LinearDiscriminatorAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(x_train, y_train)\n",
    "y_predict_sk = lda.predict(x_test)\n",
    "print(\"f1 score of scikit-learn model is: \", f1_score(y_test, y_predict_sk, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstenv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
